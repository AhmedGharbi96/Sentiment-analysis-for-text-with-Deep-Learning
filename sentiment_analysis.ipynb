{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function to read the pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove(file_path):\n",
    "    with open(file_path,'r',encoding=\"utf8\") as f:\n",
    "        vocab=set()\n",
    "        word_to_vec={}\n",
    "        word_to_index={}\n",
    "        index_to_word={}\n",
    "        for line in f:\n",
    "            line=line.strip().split()\n",
    "            vocab.add(line[0])\n",
    "            word_to_vec[line[0]]= np.array(line[1:],dtype=np.float64)\n",
    "        index=0\n",
    "        for w in sorted(vocab):\n",
    "            word_to_index[w]=index\n",
    "            index_to_word[index]=w\n",
    "            index+=1\n",
    "        return (word_to_vec,word_to_index,index_to_word)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path=\"D:/Stanford_sentiment_tree/glove.6B.50d.txt\"\n",
    "word_to_vec,word_to_index,index_to_word=read_glove(embeddings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>! '</td>\n",
       "      <td>22935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>! ''</td>\n",
       "      <td>18235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>! Alas</td>\n",
       "      <td>179257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>! Brilliant</td>\n",
       "      <td>22936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>! Brilliant !</td>\n",
       "      <td>40532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         phrases      id\n",
       "0            ! '   22935\n",
       "1           ! ''   18235\n",
       "2         ! Alas  179257\n",
       "3    ! Brilliant   22936\n",
       "4  ! Brilliant !   40532"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path=\"D:/Stanford_sentiment_tree/dictionary.txt\"\n",
    "data=pd.read_table(data_path,sep=\"|\")\n",
    "data.rename(columns={'!':\"phrases\",'0':\"id\"},inplace=True)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phrase ids</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.44444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.42708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239227</td>\n",
       "      <td>0.36111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239228</td>\n",
       "      <td>0.38889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239229</td>\n",
       "      <td>0.33333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239230</td>\n",
       "      <td>0.88889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239231</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239232 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment values\n",
       "phrase ids                  \n",
       "0                    0.50000\n",
       "1                    0.50000\n",
       "2                    0.44444\n",
       "3                    0.50000\n",
       "4                    0.42708\n",
       "...                      ...\n",
       "239227               0.36111\n",
       "239228               0.38889\n",
       "239229               0.33333\n",
       "239230               0.88889\n",
       "239231               0.50000\n",
       "\n",
       "[239232 rows x 1 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_path=data_path=\"D:/Stanford_sentiment_tree/sentiment_labels.txt\"\n",
    "labels=pd.read_table(labels_path,sep=\"|\")\n",
    "labels.head()\n",
    "labels.set_index(\"phrase ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeled=pd.merge(left=data,right=labels,left_on=\"id\",right_on=\"phrase ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>id</th>\n",
       "      <th>phrase ids</th>\n",
       "      <th>sentiment values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>! '</td>\n",
       "      <td>22935</td>\n",
       "      <td>22935</td>\n",
       "      <td>0.52778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>! ''</td>\n",
       "      <td>18235</td>\n",
       "      <td>18235</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>! Alas</td>\n",
       "      <td>179257</td>\n",
       "      <td>179257</td>\n",
       "      <td>0.44444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>! Brilliant</td>\n",
       "      <td>22936</td>\n",
       "      <td>22936</td>\n",
       "      <td>0.86111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>! Brilliant !</td>\n",
       "      <td>40532</td>\n",
       "      <td>40532</td>\n",
       "      <td>0.93056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         phrases      id  phrase ids  sentiment values\n",
       "0            ! '   22935       22935           0.52778\n",
       "1           ! ''   18235       18235           0.50000\n",
       "2         ! Alas  179257      179257           0.44444\n",
       "3    ! Brilliant   22936       22936           0.86111\n",
       "4  ! Brilliant !   40532       40532           0.93056"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_labeled[\"phrases\"].values, data_labeled[\"sentiment values\"].values, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(sentences,word_to_index,maxlen):\n",
    "    indices=np.zeros(shape=(sentences.shape[0],maxlen),dtype=np.int64)\n",
    "    vocab=word_to_index.keys()\n",
    "    for i in range(len(sentences)):\n",
    "        words= sentences[i].lower().split()\n",
    "        j=0\n",
    "        for w in words: \n",
    "            if (w in vocab):\n",
    "                indices[i,j]=word_to_index[w]\n",
    "                #print(word_to_index[w])\n",
    "                j+=1\n",
    "    return(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[390138, 264549, 222483,  71089, 336113, 345296,  60664, 360914,\n",
       "        160417,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0],\n",
       "       [151348, 193918, 132927,    451,  45130,  97034,    451,  54717,\n",
       "        151348, 357265, 111388, 357964, 357211, 204678, 280943, 163744,\n",
       "        188480, 358159, 111388, 222137,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0],\n",
       "       [   157,  51873,    323,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0],\n",
       "       [388710, 326240,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0],\n",
       "       [357411, 357639,    152,  65962, 322193,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_to_indices(X_train[0:5],word_to_index,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method that returns a pre-trained embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\envs\\V02 With Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\V02 With Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\V02 With Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\V02 With Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\V02 With Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\V02 With Keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding(word_to_vec,word_to_index):\n",
    "    vocab_len=len(word_to_index)+1\n",
    "    vec_size=word_to_vec[\"i\"].shape[0]\n",
    "    emb_matrix=np.zeros(shape=(vocab_len,vec_size))\n",
    "    for w,idx in word_to_index.items():\n",
    "        emb_matrix[idx,:]=word_to_vec[w]\n",
    "    embedding_layer = Embedding(input_dim=vocab_len,output_dim=vec_size,trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return (embedding_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer(word_to_vec,word_to_index,maxlen):\n",
    "    sentence_indices=Input(shape=(maxlen,),dtype=np.int64)\n",
    "    embedding_layer=pretrained_embedding(word_to_vec,word_to_index)\n",
    "    X=embedding_layer(sentence_indices)\n",
    "    X=LSTM(units=128,return_sequences=True)(X)\n",
    "    X=Dropout(0.5)(X)\n",
    "    X=LSTM(units=128,return_sequences=False)(X)\n",
    "    X=Dropout(0.5)(X)\n",
    "    X=Dense(1)(X)\n",
    "    X=Activation(\"sigmoid\")(X)\n",
    "    model=Model(inputs=sentence_indices,outputs=X)\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=sentiment_analyzer(word_to_vec,word_to_index,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 60, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 60, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 60, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,411\n",
      "Trainable params: 223,361\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path=\"D:/Stanford_sentiment_tree/best_model\"\n",
    "callback_checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)\n",
    "\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=2, verbose=1)\n",
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices=sentences_to_indices(X_train,word_to_index,60)\n",
    "X_test_indices=sentences_to_indices(X_test,word_to_index,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 191384 samples, validate on 47847 samples\n",
      "Epoch 1/100\n",
      "191384/191384 [==============================] - 1565s 8ms/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03064, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 2/100\n",
      "191384/191384 [==============================] - 1601s 8ms/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03064 to 0.03064, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 3/100\n",
      "191384/191384 [==============================] - 1608s 8ms/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03064 to 0.03064, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 4/100\n",
      "191384/191384 [==============================] - 1609s 8ms/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03064 to 0.01799, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 5/100\n",
      "191384/191384 [==============================] - 1612s 8ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01799 to 0.01508, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 6/100\n",
      "191384/191384 [==============================] - 1608s 8ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01508 to 0.01408, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 7/100\n",
      "191384/191384 [==============================] - 1605s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01408 to 0.01374, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 8/100\n",
      "191384/191384 [==============================] - 1608s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01374 to 0.01253, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 9/100\n",
      "191384/191384 [==============================] - 1602s 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01253 to 0.01249, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 10/100\n",
      "191384/191384 [==============================] - 1603s 8ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01249 to 0.01235, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 11/100\n",
      "191384/191384 [==============================] - 1589s 8ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01235\n",
      "Epoch 12/100\n",
      "191384/191384 [==============================] - 1563s 8ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01235 to 0.01163, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 13/100\n",
      "191384/191384 [==============================] - 1570s 8ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01163\n",
      "Epoch 14/100\n",
      "191384/191384 [==============================] - 1582s 8ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01163 to 0.01144, saving model to D:/Stanford_sentiment_tree/best_model\n",
      "Epoch 15/100\n",
      "191384/191384 [==============================] - 1588s 8ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01144\n",
      "Epoch 16/100\n",
      "191384/191384 [==============================] - 1582s 8ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01144\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1909cfc0cc0>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train_indices,y=Y_train,batch_size=32,epochs=100,callbacks=callbacks,verbose=1,\n",
    "          validation_data=(X_test_indices, Y_test))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence,word_to_index,maxlen,model):\n",
    "    sentence_to_array=np.array(sentence)\n",
    "    sentence_to_array=sentence_to_array.reshape(1)\n",
    "    sentence_to_array=sentences_to_indices(sentence_to_array,word_to_index,maxlen)\n",
    "    res=model.predict(sentence_to_array)\n",
    "    if (0<=res and res<=0.2):\n",
    "        sentiment=\"very negative\"\n",
    "    elif((0.2<res and res<=0.4)):\n",
    "        sentiment=\"negative\"\n",
    "    elif((0.4<res and res<=0.6)):\n",
    "        sentiment=\"neutral\"\n",
    "    elif((0.6<res and res<=0.8)):\n",
    "        sentiment=\"positive\"\n",
    "    else :\n",
    "        sentiment=\"very positive\"\n",
    "    print(sentiment)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "predict_sentence(\"i love being here\",word_to_index,60,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
